{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "current-technology",
   "metadata": {},
   "source": [
    "# Leveraging MLflow with SASCTL and Model Manager for SKLearn\n",
    "[MLflow](https://mlflow.org/) is an open-source platform used to manage the ML lifecycle, including experimentation, reproducibility, deployment, and a central model registry. \n",
    "\n",
    "While MLflow and Model Manager overlap in functionality, there are places where MLflow can strengthen Model Manager. For example, by leveraging MLflow, Model Manager can better support various complex model architectures. We will continue to make additions to our SASCTL integrations with MLflow, but currently we support models developed in sklearn, statsmodel, scipy, and numpy.\n",
    "\n",
    "In this notebook, we will push a model generated in MLflow into the Model Manager registry.\n",
    "***\n",
    "## Getting Started\n",
    "To import MLflow models into SAS Model Manager, there are a few lines that need to be included in the MLflow script. First, include the infer_signature function in the import statements. We will need to include the signature inference after any parameter logging is defined and include a signature argument in the model logging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-reservation",
   "metadata": {},
   "source": [
    "Next, adjust any data columns which are not valid Python variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('./data/hmeq.csv')\n",
    "data.columns = data.columns.str.replace('\\W|^(?=\\d)', '_', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-scottish",
   "metadata": {},
   "source": [
    "***\n",
    "## Building a Model\n",
    "Next, let's build a logistic regression. First, we will prepare our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values \n",
    "data = data.fillna(value={'MORTDUE': 65019, 'VALUE': 89235, 'YOJ': 7, 'DEROG': 0, 'DELINQ': 0, 'CLAGE': 173, 'NINQ': 1, 'CLNO': 20, 'DEBTINC': 35})\n",
    "\n",
    "# One-hot-encode job\n",
    "one_hot_job = pd.get_dummies(data[\"JOB\"], prefix = \"JOB\", drop_first=True)\n",
    "data = data.join(one_hot_job)\n",
    "data = data.drop('JOB', axis = 1)\n",
    "\n",
    "# One-hot-encode reason\n",
    "one_hot_reason = pd.get_dummies(data[\"REASON\"], prefix = \"REASON\", drop_first=True)\n",
    "data = data.join(one_hot_reason)\n",
    "data = data.drop('REASON', axis = 1)\n",
    "\n",
    "# Separate target \n",
    "y = data.pop('BAD').values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-window",
   "metadata": {},
   "source": [
    "Next, we will build our SKLearn model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression().fit(data, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-seller",
   "metadata": {},
   "source": [
    "Now, let’s generate our signature. For this simple example, I’m assuming that this model will not encounter missing values, so I am ignoring MLflow’s warning about missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "signature = infer_signature(data, model.predict(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-entrance",
   "metadata": {},
   "source": [
    "Finally, let’s log our MLflow model and include our signature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "os.chdir(\"./data/MLFlowModels/\")\n",
    "    \n",
    "score = model.score(data, y)\n",
    "\n",
    "print(\"Score: %s\" % score)\n",
    "mlflow.log_metric(\"score\", score)\n",
    "\n",
    "mlflow.sklearn.log_model(model, \"model\", signature=signature)\n",
    "print(\"Model saved in run %s\" % mlflow.active_run().info.run_uuid)\n",
    "\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-momentum",
   "metadata": {},
   "source": [
    "## Register Model\n",
    "Now, let’s use SASCTL to register our MLflow SKLearn model. First, let’s install the necessary packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pathing support\n",
    "from pathlib import Path\n",
    "\n",
    "# sasctl interface for importing models\n",
    "import sasctl.pzmm as pzmm \n",
    "from sasctl import Session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-ideal",
   "metadata": {},
   "source": [
    "And point SASCTL to the MLflow model files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlPath = Path(f'./data/MLFlowModels/mlruns/0/{mlflow.active_run().info.run_uuid}/artifacts/model')\n",
    "varDict, inputsDict, outputsDict = pzmm.MLFlowModel.read_mlflow_model_file(m_path=mlPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-gentleman",
   "metadata": {},
   "source": [
    "Next, let’s create a folder for our SASCTL assets and pickle our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPrefix = 'MLFlowDemo'\n",
    "zipFolder = Path.cwd() / f'data/MLFlowModels/{modelPrefix}'\n",
    "pzmm.PickleModel.pickle_trained_model(model_prefix=modelPrefix, pickle_path=zipFolder, mlflow_details=varDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-latex",
   "metadata": {},
   "source": [
    "We can leverage the information from MLflow to generate metadata files for SASCTL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "J = pzmm.JSONFiles()\n",
    "J.write_var_json(inputsDict, isInput=True, jPath=zipFolder)\n",
    "J.write_var_json(outputsDict, isInput=False, jPath=zipFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write model properties to a json file\n",
    "J.write_model_properties_json(modelName=modelPrefix,\n",
    "                            modelDesc='MLFlow Model ',\n",
    "                            targetVariable='BAD',\n",
    "                            modelType='Logistic Regression',\n",
    "                            modelPredictors='',\n",
    "                            targetEvent=1,\n",
    "                            numTargetCategories=1,\n",
    "                            eventProbVar='tensor',\n",
    "                            jPath=zipFolder,\n",
    "                            modeler='sasdemo')\n",
    "\n",
    "# Write model metadata to a json file\n",
    "J.write_file_metadata_json(modelPrefix, jPath=zipFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-pacific",
   "metadata": {},
   "source": [
    "We have generated our metadata and modeling assets. Next, we will need our SAS Viya host, username, and password to create a session within SASCTL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-bracelet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "username = getpass.getpass(\"Username: \")\n",
    "password = getpass.getpass(\"Password: \")\n",
    "host = getpass.getpass(\"Hostname: \")\n",
    "sess = Session(host, username, password, protocol='http')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-excess",
   "metadata": {},
   "source": [
    "We can use our session to push our modeling assets into Model Manager. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-playing",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = pzmm.ImportModel()\n",
    "I.import_model(zipFolder, modelPrefix, 'MLFlowTest', inputsDict, None, '{}.predict({})', metrics=['tensor'], force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-bryan",
   "metadata": {},
   "source": [
    "Success! Now we can view our model score code, pickle file, and metadata within Model Manager. \n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Copyright Â© 2021, SAS Institute Inc., Cary, NC, USA.  All Rights Reserved.\n",
    "SPDX-License-Identifier: Apache-2.0"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# HMEQ Dataset : Build and Import Trained Models into SAS Model Manager\n",
    "\n",
    "This notebook provides an example of how to build and train a Python model and then import the model into SAS Model Manager using the fleet maintenance data set. Lines of code that must be modified by the user, such as directory paths are noted with the comment \"_Changes required by user._\".\n",
    "\n",
    "_**Note:** If you download only this notebook and not the rest of the repository, you must also download the hmeq.csv file from the data folder in the examples directory. These files are used when executing this notebook example._\n",
    "\n",
    "Here are the steps shown in this notebook:\n",
    "\n",
    "1. Import and review data and preprocess for model training.\n",
    "2. Build, train, and access a decision tree, random forest, and gradient boosting model.\n",
    "3. Serialize the models into separate pickle files.\n",
    "4. Write the metadata JSON files needed for importing into SAS Model Manager as well as optional files for fit statistics and ROC/Lift charts.\n",
    "4. Write a score code Python file for model scoring.\n",
    "5. Zip the pickle, JSON, and score code files into an archive file.\n",
    "6. Import the ZIP archive file to SAS Model Manager via the Session object and relevant function call."
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Python Package Imports"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Dataframes for data manipulations\r\n",
    "import pandas as pd\r\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\r\n",
    "# Mathematical calculations and array handling\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "# Data partitioning for TRAIN and TEST data sets\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "# Decision tree, random forest, and gradient boosting models\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\r\n",
    "# Model assessments \r\n",
    "from sklearn.metrics import classification_report, confusion_matrix\r\n",
    "\r\n",
    "# Embedded plotting\r\n",
    "import matplotlib.pyplot as plt \r\n",
    "plt.rc(\"font\", size=14)\r\n",
    "\r\n",
    "# Pathing support\r\n",
    "from pathlib import Path\r\n",
    "\r\n",
    "# sasctl interface for importing models\r\n",
    "import sasctl.pzmm as pzmm\r\n",
    "from sasctl import Session"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import and Review Data Set"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "hmeqData = pd.read_csv('data/hmeq.csv',sep= ',')\r\n",
    "hmeqData.shape"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "hmeqData.head()"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "hmeqData.hist(figsize=(15,15), layout=(4, 4));"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "hmeqData.columns"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocess Data"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predictorColumns = ['LOAN', 'MORTDUE', 'VALUE', 'YOJ', 'DEROG', 'DELINQ', 'CLAGE', 'NINQ', 'CLNO', 'DEBTINC']\r\n",
    "\r\n",
    "targetColumn = 'BAD'\r\n",
    "x = hmeqData[predictorColumns]\r\n",
    "y = hmeqData[targetColumn]\r\n",
    "\r\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size=0.3, random_state=42)\r\n",
    "\r\n",
    "# For missing values, impute the data set's mean value\r\n",
    "xTest.fillna(xTest.mean(), inplace=True)\r\n",
    "xTrain.fillna(xTrain.mean(), inplace=True)"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create, Train, and Assess Model"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "treeModel = DecisionTreeClassifier(random_state=42)\r\n",
    "treeModel = treeModel.fit(xTrain, yTrain)\r\n",
    "\r\n",
    "forestModel = RandomForestClassifier(random_state=42)\r\n",
    "forestModel = forestModel.fit(xTrain, yTrain)\r\n",
    "\r\n",
    "gradientModel = GradientBoostingClassifier(random_state=42)\r\n",
    "gradientModel = gradientModel.fit(xTrain, yTrain)"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def sortFeatureImportance(model, xData):\r\n",
    "    features = {}\r\n",
    "    for importance, name in sorted(zip(model.feature_importances_, xData.columns), reverse=True):\r\n",
    "        features[name] = str(np.round(importance*100, 2)) + '%'\r\n",
    "    return features\r\n",
    "\r\n",
    "importances = pd.DataFrame.from_dict(sortFeatureImportance(treeModel, xTrain), orient='index').rename(columns={0: 'DecisionTree'})\r\n",
    "importances['RandomForest'] = pd.DataFrame.from_dict(sortFeatureImportance(forestModel, xTrain), orient='index')\r\n",
    "importances['GradientBoosting'] = pd.DataFrame.from_dict(sortFeatureImportance(gradientModel, xTrain), orient='index')\r\n",
    "importances"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "yTreePredict = treeModel.predict(xTest)\r\n",
    "yTreeProba = treeModel.predict_proba(xTest)\r\n",
    "print(confusion_matrix(yTest, yTreePredict))\r\n",
    "print(classification_report(yTest, yTreePredict))\r\n",
    "print('Decision Tree Model Accuracy = ' + str(np.round(treeModel.score(xTest, yTest)*100,2)) + '%')"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "yForestPredict = forestModel.predict(xTest)\r\n",
    "yForestProba = forestModel.predict_proba(xTest)\r\n",
    "print(confusion_matrix(yTest, yForestPredict))\r\n",
    "print(classification_report(yTest, yForestPredict))\r\n",
    "print('Random Forest Model Accuracy = ' + str(np.round(forestModel.score(xTest, yTest)*100,2)) + '%')"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "yGradientPredict = gradientModel.predict(xTest)\r\n",
    "yGradientProba = gradientModel.predict_proba(xTest)\r\n",
    "print(confusion_matrix(yTest, yGradientPredict))\r\n",
    "print(classification_report(yTest, yGradientPredict))\r\n",
    "print('Gradient Boosting Model Accuracy = ' + str(np.round(gradientModel.score(xTest, yTest)*100,2)) + '%')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Register Model in SAS Model Manager with pzmm"
   ],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "modelPrefix = ['DecisionTreeClassifier', 'RandomForest', 'GradientBoosting']\r\n",
    "zipFolder = [Path.cwd() / 'data/hmeqModels/DecisionTreeClassifier/',\r\n",
    "             Path.cwd() / 'data/hmeqModels/RandomForest/',\r\n",
    "             Path.cwd() / 'data/hmeqModels/GradientBoosting'] # User created directories\r\n",
    "model = [treeModel, forestModel, gradientModel]\r\n",
    "\r\n",
    "for (m, prefix, path) in zip(model, modelPrefix, zipFolder):\r\n",
    "    pzmm.PickleModel.pickleTrainedModel(_, m, prefix, path)"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def writeJSONFiles(data, predict, target, zipFolder, yTrain, modelPrefix):\r\n",
    "    J = pzmm.JSONFiles()\r\n",
    "    \r\n",
    "    # Write input variable mapping to a json file\r\n",
    "    J.writeVarJSON(data[predict], isInput=True, jPath=zipFolder)\r\n",
    "    \r\n",
    "    # Set output variables and assign an event threshold, then write output variable mapping\r\n",
    "    outputVar = pd.DataFrame(columns=['EM_EVENTPROBABILITY', 'EM_CLASSIFICATION'])\r\n",
    "    outputVar['EM_CLASSIFICATION'] = yTrain.astype('category').cat.categories.astype('str')\r\n",
    "    outputVar['EM_EVENTPROBABILITY'] = 0.5 # Event threshold\r\n",
    "    J.writeVarJSON(outputVar, isInput=False, jPath=zipFolder)\r\n",
    "    \r\n",
    "    # Write model properties to a json file\r\n",
    "    J.writeModelPropertiesJSON(modelName=modelPrefix,\r\n",
    "                               modelDesc='',\r\n",
    "                               targetVariable=target,\r\n",
    "                               modelType='',\r\n",
    "                               modelPredictors=predict,\r\n",
    "                               targetEvent=1,\r\n",
    "                               numTargetCategories=1,\r\n",
    "                               eventProbVar='EM_EVENTPROBABILITY',\r\n",
    "                               jPath=zipFolder,\r\n",
    "                               modeler='sasdemo')\r\n",
    "    \r\n",
    "    # Write model metadata to a json file\r\n",
    "    J.writeFileMetadataJSON(modelPrefix, jPath=zipFolder)\r\n",
    "\r\n",
    "for (prefix, path) in zip(modelPrefix, zipFolder):\r\n",
    "    writeJSONFiles(hmeqData, predictorColumns, targetColumn, path, yTrain, prefix)"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import getpass\r\n",
    "def writeModelStats(xTrain, yTrain, testProba, yTest, model, target, zipFolder, conn):\r\n",
    "    J = pzmm.JSONFiles()\r\n",
    "    \r\n",
    "    # Calculate train predictions\r\n",
    "    trainProba = model.predict_proba(xTrain)\r\n",
    "    \r\n",
    "    # Assign data to lists of actual and predicted values\r\n",
    "    trainData = pd.concat([yTrain.reset_index(drop=True), pd.Series(data=trainProba[:,1])], axis=1)\r\n",
    "    testData = pd.concat([yTest.reset_index(drop=True), pd.Series(data=testProba[:,1])], axis=1)\r\n",
    "    \r\n",
    "    # Calculate the model statistics and write to json files\r\n",
    "    J.calculateFitStat(trainData=trainData, testData=testData, jPath=zipFolder)\r\n",
    "    J.generateROCLiftStat(target, 1, conn, trainData=trainData, testData=testData, jPath=zipFolder)\r\n",
    "    \r\n",
    "username = getpass.getpass()\r\n",
    "password = getpass.getpass()\r\n",
    "host = 'demo.sas.com'\r\n",
    "sess = Session(host, username, password, protocol='http')\r\n",
    "conn = sess.as_swat()\r\n",
    "\r\n",
    "testProba = [yTreeProba, yForestProba, yGradientProba]\r\n",
    "for (m, proba, path) in zip(model, testProba, zipFolder):\r\n",
    "    writeModelStats(xTrain, yTrain, proba, yTest, m, targetColumn, path, conn)"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "I = pzmm.ImportModel()\r\n",
    "for (prefix, path) in zip(modelPrefix, zipFolder):\r\n",
    "    I.pzmmImportModel(path, prefix, 'HMEQModels', x, y, '{}.predict({})', force=True)"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('dev-sasctl': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "interpreter": {
   "hash": "f9708d3f38eeab835578f0695c8890716ee809285281a28db6e379a5abca1310"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
name: "Build"
on: [push, workflow_dispatch]
jobs:
  codeanalysis:
    name: "Code Quality"
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Black
        uses: psf/black@stable
        with:
          src: "./src ./tests"

  test:
    name: "Test"
    runs-on: ${{ matrix.os-version }}
    env:
      LANG: en_US.UTF-8
    strategy:
      matrix:
        python-version: ['3.6', '3.7', '3.8', '3.9', '3.10']
        os-version: ['ubuntu-20.04', 'windows-latest', 'macos-latest']
# Pinned Ubuntu version to 20.04 since no Python 3.6 builds available on ubuntu-latest (22.04) as of 2022-12-7.
#        os-version: [ubuntu-latest, windows-latest, macos-latest]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies (Ubuntu)
        if: startsWith(matrix.os-version, 'ubuntu')
        run: |
          sudo apt-get update
          sudo apt-get install build-essential libkrb5-dev

      - name: Install dependencies (Common)
        run: |
          # Setup tox & code coverage
          pip install --upgrade pip
          pip install tox tox-gh-actions pytest pytest-cov scikit-learn

      - name: Run Tests
        run: |
          tox

      # Separate upload task for unit test coverage allows for flagged analysis of test coverage
      - name: Upload Unit Test Coverage
        if: startsWith(matrix.os-version, 'ubuntu')
        uses: codecov/codecov-action@v3
        with:
          directory: ./.reports/
          fail_ci_if_error: false
          file: unit.xml
          flags: unit
          verbose: true

      # Separate upload task for integration test coverage allows for flagged analysis of test coverage
      - name: Upload Integration Test Coverage
        if: startsWith(matrix.os-version, 'ubuntu')
        uses: codecov/codecov-action@v3
        with:
          directory: ./.reports/
          fail_ci_if_error: false
          file: integration.xml
          flags: integration
          verbose: true

# Uncomment when scenario test cases are working again
#      Separate upload task for scenario test coverage allows for flagged analysis of test coverage
#      - name: Upload Scenario Test Coverage
#        if: matrix.os-version == 'ubuntu-latest'
#        uses: codecov/codecov-action@v3
#        with:
#          directory: ./.reports/
#          fail_ci_if_error: true
#          file: scenarios.xml
#          flags: scenarios
#          verbose: true

  gh-pages:
    name: "Build Documentation"
    runs-on: ubuntu-latest
    needs: test
    if: startsWith(github.ref, 'refs/tags/') # run only on tagged commits

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.9

      - name: Setup environment
        run: |
          mv doc docs
          sudo apt-get install build-essential
          pip install sphinx six pyyaml pandas pydata-sphinx-theme numpydoc

      - name: Check documentation
        uses: ammaraskar/sphinx-problem-matcher@master

      - name: Build documentation
        run: sphinx-build -Ean -b html -j auto -D todo_include_todos=0 ./docs ./docs/_build/html

      - name: Archive artifacts
        uses: actions/upload-artifact@v2
        with:
          name: html-docs
          path: ./docs/_build/html

  # Build a package for distribution through PyPI.org (pip install sasctl)
  build_pypi:
    name: "Build PyPI Package"
    runs-on: ubuntu-latest
    needs: test
    if: startsWith(github.ref, 'refs/tags/')  # run only on tagged commits

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v2

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install setuptools wheel twine

      - name: Build Package
        run: |
          python setup.py sdist bdist_wheel

      - name: Extract Changes
        shell: python
        run: |
          import os, re
          tag_name = os.environ['GITHUB_REF'].replace('refs/tags/', '')
          changes = ''
          with open('CHANGELOG.md') as f:
              lines = f.read()
          match = re.search('%s [()\d\-\s]*' % tag_name, lines)
          if match:
              lines = lines[match.end():]
              changes = re.split('-----+', lines)[0].split('\n')
              changes = '\n'.join(changes[:-2])
          with open('release_notes.md', 'w') as f:
              f.write(changes)

      - name: Archive distribution artifacts
        # Archive distribution files for use by auto (or manual) PyPI upload
        uses: actions/upload-artifact@v3
        with:
          name: pypi-dist
          path: ./dist

      - name: Archive changelog artifacts
        uses: actions/upload-artifact@v3
        with:
          name: release_notes
          path: release_notes.md

  # Build a package for distribution through Anaconda.org (conda install sasctl)
  build_conda:
    name: "Build Conda Package"
    runs-on: ubuntu-latest
    needs: test
    if: startsWith(github.ref, 'refs/tags/') # run only on tagged commits

    steps:
      # Setup Miniconda
      - uses: conda-incubator/setup-miniconda@v2
        with:
          auto-update-conda: true

      - name: Install conda-build
        shell: bash -l {0}
        run: |
          conda install conda-build

      - name: Checkout repository
        uses: actions/checkout@v3

      # Build package and store results in .build folder
      - name: Build package
        shell: bash -l {0}
        run: |
          conda build --output-folder .build .conda

      # Archive distribution files.  Will upload in a downstream job.
      - name: Archive distribution artifacts
        uses: actions/upload-artifact@v3
        with:
          name: conda-dist
          path: .build


  # Publishes the new package to PyPI, uploads the latest documentation to GitHub Pages
  # and creates a new release with change notes on GitHub.
  publish:
    name: "Publish"
    runs-on: ubuntu-latest
    needs: [gh-pages, build_pypi, build_conda]

    steps:
      - name: Download documentation
        uses: actions/download-artifact@v3
        with:
          name: html-docs
          path: ./html-docs

      - name: Download release
        uses: actions/download-artifact@v3
        with:
          name: pypi-dist
          path: ./dist

      - name: Download release notes
        uses: actions/download-artifact@v3
        with:
          name: release_notes

      - name: Zip Documentation
        run: zip -r documentation.zip ./html-docs

      - name: Display structure of downloaded files
        run: ls -R

      # Create a draft release on GitHub
      - name: Create Release
        id: create_release
        uses: softprops/action-gh-release@v1
        with:
          draft: true
          body_path: release_notes.md
          body: ""
          files: documentation.zip

      # Publish the documentation to GitHub Pages
      - name: Deploy documentation
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./html-docs

      - name: Publish to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          user: __token__
          password: ${{ secrets.PYPI_API_TOKEN }}
          verbose: true

      # Publish the release on GitHub (remove draft status)
      - name: Publish release
        uses: StuYarrow/publish-release@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          id: ${{ steps.create_release.outputs.id }}


  # Uploads the package to Anaconda.
  # NOTE: could be merged with `publish` job above.  Left as a separate, final job since it
  #       involves multiple steps to setup the environment and if this job fails, the package
  #       has already been made available through pip, and the release info published.
  upload_conda:
    name: "Upload Conda Package"
    runs-on: ubuntu-latest
    needs: [publish]

    steps:
      # Setup Miniconda
      - uses: conda-incubator/setup-miniconda@v2
        with:
          auto-update-conda: true

      # Setup Anaconda client (required for upload)
      - name: Install anaconda client
        shell: bash -l {0}
        run: |
          conda install anaconda-client

      # Download release files
      - name: Download release
        uses: actions/download-artifact@v3
        with:
          name: conda-dist
          path: ./dist

      # Upload release to Anaconda.org
      - name: Upload release
        shell: bash -l {0}
        run: |
          anaconda -t ${{ secrets.ANACONDA_TOKEN }} upload -u sas-institute ./dist/noarch/sasctl-*.tar.bz2